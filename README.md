# DA-in-GameDev-lab5
# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ [in GameDev]
Отчет по лабораторной работе #5 выполнил(а):
- Балаба Софья Николаевна
- РИ-210940
Отметка о выполнении заданий (заполняется студентом):

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | * | 60 |
| Задание 2 | * | 20 |
| Задание 3 | * | 20 |

знак "*" - задание выполнено; знак "#" - задание не выполнено;

Работу проверили:
- к.т.н., доцент Денисов Д.В.
- к.э.н., доцент Панов М.А.
- ст. преп., Фадеев В.О.

[![N|Solid](https://cldup.com/dTxpPi9lDf.thumb.png)](https://nodesource.com/products/nsolid)

[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)

Структура отчета

- Данные о работе: название работы, фио, группа, выполненные задания.
- Цель работы.
- Задание 1.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 2.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 3.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Выводы.
- ✨Magic ✨

## Цель работы
Научиться интегрировать экономическую систему в Unity и обучить ей пользоваться Ml Agent.

## Задание 1
### Интегрировать экономическую систему в проект Unity и обучить Ml Agent.
Открыла проект в Unity, установила требуемые пакеты, добавила в проект ML-Agent.
Запустила обучение агента и сам проект.
![start](https://user-images.githubusercontent.com/102922461/204279393-b3728ab5-76f1-4b97-ba47-fca2a26c1560.jpg)


## Задание 2
### Измените параметры файла. yaml-агента и определить какие параметры и как влияют на обучение модели

Установила и запустила TensorBoard. Получила следующие графики: epsilon: 0.2 => 0.4, batch-size: 1024 => 2200, num-layers: 2 => 4
![2graphs](https://user-images.githubusercontent.com/102922461/204279623-d9dac555-da3d-42a9-adf7-9fc1f21ac9e3.jpg) 

Изменила конфигурацию агента:
![Скриншот 28-11-2022 173247](https://user-images.githubusercontent.com/102922461/204279628-234c096f-f565-41b6-abdd-2b477ec1fff7.jpg)

Графики после изменения значений:
![economic_training](https://user-images.githubusercontent.com/102922461/204279618-6c495513-74ee-49e0-901d-bfebe85cb207.jpg)
![after_conf](https://user-images.githubusercontent.com/102922461/204279633-98a17c44-8401-4cd3-a9d8-e5e851cc2073.jpg)


- График Cumulative Reward - это вознаграждение. Это значение следует максимизировать и приближать к единице.

- График Episode Length - чем меньше данное значение (эпизод), тем эффективнее обучение.

- График Policy Loss - изменение политики.

- График Entropy - чем меньше величина, тем меньше агенту нужно изучить.

- График Learning Rate - это значение должно постепенно уменьшаться.

## Вывод
В данной лабораторной при помощи ml-агента выполнила простую реализацию поиска параметров сбалансированной экономической системы. Конкретно в данной реализации, чтобы уменьшить значение темпа инфляции((цена текущего месяца - цена предыдущего месяца / цена предыдущего месяца)*100) используется ml-агент для подбора параметров(стоимость кирки, скорость добычи золота, количество добываемого золота, скорость передвижения и процент прибыли).
В ходе выполнения данной работы я на практике поняла корреляцию конфигураций ML-агента и качество и скорость обучения на примере простой экономической системы. Воспользовалась библиотекой TensorBoard для визуализации метрик обучения агента и определения конфигурации способствующие быстрому и качественному обучению. Изменила количество слоёв, размер выборки, epsilon и как итог у меня получилось успешно обучить агента - этому свидетельствуют приложенные графики.

## Powered by

**BigDigital Team: Denisov | Fadeev | Panov**
